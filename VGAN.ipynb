{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJlLi6bF13CwMEEUKy1VWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Isi2000/GAN/blob/main/VGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VANILLA GAN\n",
        "\n",
        "This notebook aims at creating an implementation of the vanilla **Vanilla GAN**\n",
        "described in the first 2 chapters of YANG WANG's paper (note that it was first Goodfellow's idea)\n",
        "\n",
        "It takes most of the code form Sovit Ranjan Rath's code **\"Generating MNIST Digit Images using Vanilla GAN with PyTorch\"**"
      ],
      "metadata": {
        "id": "rjd9hNN1ixPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.io import read_image\n",
        "\n",
        "# keras-style network summary\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "0VzbWoOtQXRv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "E_3HeczCFAVA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I only need data to train, not test (this of course is half true)\n",
        "training_data = MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "batch_size = 256\n",
        "\n",
        "train_loader = DataLoader(training_data, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "v4hRsxwWjir4"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    print(img.size())\n",
        "    plt.title(label)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "OrxkdtKAjmWi",
        "outputId": "ad0bd8d1-6fa2-4171-f32c-b2cd901c5707"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n",
            "torch.Size([1, 28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    print(\"Congratulations, you have a GPU!\")\n",
        "else:\n",
        "    print(\"PyTorch cannot see your GPU :(\")\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVbQDb98kEJu",
        "outputId": "1bcad40b-44b0-4e54-92fe-cb8a3036c90c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch cannot see your GPU :(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discriminator\n",
        "\n",
        "Be careful, this nn is a bit weird. It can classify the images but its main focus is that of recognizing true images from fake ones"
      ],
      "metadata": {
        "id": "hZZZP3VjEYWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#while formally correct first implementation must choose clarity over performance\n",
        "#No convolution, let's write a simple MLP\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, filters: list, activation=F.leaky_relu, kernel=3):\n",
        "        super().__init__()\n",
        "        filters = [1] + filters\n",
        "        # NOTE: never ever add layers into python's list...\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.fc = nn.ModuleList()\n",
        "        self.activation = activation\n",
        "\n",
        "        # define convolutions\n",
        "        for i, num_filters in enumerate(filters[1:]):\n",
        "            conv = nn.Conv2d(in_channels=filters[i], out_channels=num_filters,\n",
        "                             kernel_size=kernel, padding='same')\n",
        "\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.convs):\n",
        "            x = self.activation(layer(x))\n",
        "\n",
        "            if i % 4 == 1:\n",
        "                # downsample by 2 on 2nd conv layer\n",
        "                x = self.max_pool(x)\n",
        "        return F.sigmoid(x)\n",
        "\n",
        "netG= Discriminator(filters=[4, 4, 8, 8], kernel=3).to(device)\n",
        "\n",
        "summary(netG, (1,28,28), device ='cuda')\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "w3gv8dYdkbKH",
        "outputId": "59e3c2a8-6641-444a-af5f-6ef4cc880bf9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\nclass Discriminator(nn.Module):\\n    def __init__(self, filters: list, activation=F.leaky_relu, kernel=3):\\n        super().__init__()\\n        filters = [1] + filters\\n        # NOTE: never ever add layers into python's list...\\n        self.convs = nn.ModuleList()\\n        self.fc = nn.ModuleList()\\n        self.activation = activation\\n\\n        # define convolutions\\n        for i, num_filters in enumerate(filters[1:]):\\n            conv = nn.Conv2d(in_channels=filters[i], out_channels=num_filters,\\n                             kernel_size=kernel, padding='same')\\n\\n            self.convs.append(conv)\\n\\n        self.max_pool = nn.MaxPool2d(2, 2)\\n\\n    def forward(self, x):\\n        for i, layer in enumerate(self.convs):\\n            x = self.activation(layer(x))\\n\\n            if i % 4 == 1:\\n                # downsample by 2 on 2nd conv layer\\n                x = self.max_pool(x)\\n        return F.sigmoid(x)\\n\\nnetG= Discriminator(filters=[4, 4, 8, 8], kernel=3).to(device)\\n\\nsummary(netG, (1,28,28), device ='cuda')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.activation import LeakyReLU\n",
        "noiz = 128 #arbitrary size of the latent vector,\n",
        "\n",
        "######!!!!!!!!!!!ATTENTION TO NOIZ!!!!!!!!!!!!!!!!############\n",
        "#It was a really dumb way to name something, everything should work, but in case of error look here first!!!!!!!!!!\n",
        "#################!!!!!!!!!!!!!!!!!!!!!!!!!###############\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise):\n",
        "    super(Generator, self).__init__()\n",
        "    self.noise = noiz\n",
        "\n",
        "    #usually I despise this way of working, but for such an easy case I can make an exeption\n",
        "    self.main = nn.Sequential(\n",
        "        nn.Linear(self.noise, 256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Linear(256, 512),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Linear(512, 1024),\n",
        "        nn.LeakyReLU(0.2),\n",
        "\n",
        "        nn.Linear(1024, 784),\n",
        "        nn.Tanh(),\n",
        "        )\n",
        "  def forward(self, x):\n",
        "    return self.main(x).view(-1, 1, 28, 28)\n",
        "\n",
        "netG = Generator(128).to(device)\n",
        "summary(netG, (1, 128), device = 'cuda')"
      ],
      "metadata": {
        "id": "SAB47BplGqxp",
        "outputId": "f6d20ebd-2673-4c41-937b-3879d0db24fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1               [-1, 1, 256]          33,024\n",
            "         LeakyReLU-2               [-1, 1, 256]               0\n",
            "            Linear-3               [-1, 1, 512]         131,584\n",
            "         LeakyReLU-4               [-1, 1, 512]               0\n",
            "            Linear-5              [-1, 1, 1024]         525,312\n",
            "         LeakyReLU-6              [-1, 1, 1024]               0\n",
            "            Linear-7               [-1, 1, 784]         803,600\n",
            "              Tanh-8               [-1, 1, 784]               0\n",
            "================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,493,520\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 5.70\n",
            "Estimated Total Size (MB): 5.74\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.n_input = 784\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(self.n_input, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        return self.main(x)\n",
        "\n",
        "netD = Discriminator().to(device)\n",
        "summary(netD, (1,28,28), device = 'cuda')"
      ],
      "metadata": {
        "id": "IcOM3p6_kr3I",
        "outputId": "024b42aa-41d3-4262-8004-a192a0e3c90c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 1024]         803,840\n",
            "         LeakyReLU-2                 [-1, 1024]               0\n",
            "           Dropout-3                 [-1, 1024]               0\n",
            "            Linear-4                  [-1, 512]         524,800\n",
            "         LeakyReLU-5                  [-1, 512]               0\n",
            "           Dropout-6                  [-1, 512]               0\n",
            "            Linear-7                  [-1, 256]         131,328\n",
            "         LeakyReLU-8                  [-1, 256]               0\n",
            "           Dropout-9                  [-1, 256]               0\n",
            "           Linear-10                    [-1, 1]             257\n",
            "          Sigmoid-11                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 1,460,225\n",
            "Trainable params: 1,460,225\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.04\n",
            "Params size (MB): 5.57\n",
            "Estimated Total Size (MB): 5.61\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optim_g = optim.Adam(netG.parameters(), lr=0.0002)\n",
        "optim_d = optim.Adam(netD.parameters(), lr=0.0002)"
      ],
      "metadata": {
        "id": "7pc7GnIpKVnk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "losses_g = [] # to store generator loss after each epoch\n",
        "losses_d = [] # to store discriminator loss after each epoch\n",
        "images = [] # to store images generatd by the generator"
      ],
      "metadata": {
        "id": "EB4ngWTbKhX1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "\n",
        "These functions will come in handy during the training and visualization"
      ],
      "metadata": {
        "id": "beF1LMCRpa2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to create real labels (1s), basically real data\n",
        "def label_real(size):\n",
        "    \"\"\"to create real labels (1s), basically real data\"\"\"\n",
        "    data = torch.ones(size, 1)\n",
        "    return data.to(device)\n",
        "def label_fake(size):\n",
        "    \"\"\"to create fake labels (0s), basically fake data\"\"\"\n",
        "    data = torch.zeros(size, 1)\n",
        "    return data.to(device)"
      ],
      "metadata": {
        "id": "cI0GMYmaK1t2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nz(sample_size, noiz):\n",
        "  \"\"\"creates the noise vector\"\"\"\n",
        "  return torch.randn(sample_size, noiz).to(device) #random noise from a N(0,1), with size sample_size x noise\n",
        "\n",
        "print(nz(200, 128))"
      ],
      "metadata": {
        "id": "Wq38blaapomn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import save_image\n",
        "def save_gen_img(img, path):\n",
        "  save_imgage(img, path)"
      ],
      "metadata": {
        "id": "L88dvhKdqI1H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TRAINING\n",
        "\n",
        "First we define the train functions for discriminator and generator"
      ],
      "metadata": {
        "id": "g07kFu5OradX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we need to train him in order to distinguish fake images from real ones\n",
        "\n",
        "def train_discriminator(optimizer, real_data, fake_data):\n",
        "  batch_size = 128\n",
        "  real_label = label_real(b_size)\n",
        "  fake_label = label_fake(b_size)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  output_real = netD(real_data)\n",
        "  loss_real = criterion(output_real, real_label)\n",
        "\n",
        "  output_fake = nedD(fake_data)\n",
        "  loss_fake = criterion(output_fake, fake_label)\n",
        "\n",
        "  loss_real.backward()\n",
        "  loss_fake.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss_real + loss_fake #total loss is what intrests us the most\n",
        "\n"
      ],
      "metadata": {
        "id": "f5DU5Pv-rbcq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#now we need to train the gen in order to be able to fool the discriminator\n",
        "\n",
        "def train_generator(optimizer, fake_data): #I only pass him fake data since it's the one it's producing\n",
        "  batch_size = 128\n",
        "  real_label = label_real(128)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  output = netD(data_fake) #STILL THE DISCRIMINATOR!!!!\n",
        "\n",
        "  loss = criterion(output, real_label)\n",
        "\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "GCnN8qH5sYtO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#not a great fan of tqdm, but it indeed is a great tool for data visualization\n",
        "from tqdm import tqdm #progress bars\n"
      ],
      "metadata": {
        "id": "Hy9Hx3Nvt-7f"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRAINING LOOP"
      ],
      "metadata": {
        "id": "WwGt1ieuvGbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200 #num_iterations for training\n",
        "k = 3 #iter to run the discriminator\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss_g = 0.0\n",
        "  logg_d = 0.0\n",
        "  for batch_index, data in tqdm(enumerate(train_loader), total=int(len(training_data)/train_loader.batch_size)):\n",
        "\n",
        "    image, _ = data\n",
        "    image = image.to(device)\n",
        "    b_size = len(image)\n",
        "\n",
        "    for step in range(k):\n",
        "      fake_data = netG(nz(b_size, noiz)).detach() #img only\n",
        "      data_real = image\n",
        "\n",
        "      loss_d += train_discriminator(optim_d, data_real, data_fake)\n",
        "\n",
        "    #here I start training the gen\n",
        "    data_fake = netG(nz(b_size, noiz))\n",
        "    # train the generator network\n",
        "    loss_g += train_generator(optim_g, data_fake)\n",
        "\n",
        "    # create the final fake image for the epoch\n",
        "    generated_img = generator(noise).cpu().detach()\n",
        "    # make the images as grid\n",
        "    generated_img = make_grid(generated_img)\n",
        "    # save the generated torch tensor models to disk\n",
        "    save_generator_image(generated_img, f\"../outputs/gen_img{epoch}.png\")\n",
        "    images.append(generated_img)\n",
        "    epoch_loss_g = loss_g / bi # total generator loss for the epoch\n",
        "    epoch_loss_d = loss_d / bi # total discriminator loss for the epoch\n",
        "    losses_g.append(epoch_loss_g)\n",
        "    losses_d.append(epoch_loss_d)\n",
        "\n",
        "    print(f\"Epoch {epoch} of {epochs}\")\n",
        "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "VjmAMP1Iu7dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oKSsFkRvvrZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}